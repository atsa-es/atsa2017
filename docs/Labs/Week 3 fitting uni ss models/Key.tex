%\renewcommand{\rightmark}{Homework solutions}

\chapter*{Solutions Chapter \ref{chap:univariate state-space}}
\addcontentsline{toc}{chapter}{Solutions Chapter \ref{chap:univariate state-space}}

%\chapter{Key and explanations for Homework Week 3}
\subsection*{Data Set Up}
\begin{Schunk}
\begin{Sinput}
 library(MARSS)
 dat=log(grouse[,2])
\end{Sinput}
\end{Schunk}


\subsection*{Problem 1}
\begin{wideenumerate}
\item Plot the data.
\begin{Schunk}
\begin{Sinput}
 plot(grouse[,1], dat, type="l", ylab="log count", xlab="")
\end{Sinput}
\end{Schunk}
\begin{figure}[htp]
\begin{center}
\includegraphics{../figures/HWUSS--hw1-fig-plot}
\end{center}
\end{figure}
\item Fit each model using \verb@MARSS()@.
\begin{Schunk}
\begin{Sinput}
 mod.list1=list(
   B=matrix(1), U=matrix(0), Q=matrix("q"),
   Z=matrix(1), A=matrix(0), R=matrix(0),
   x0=matrix("a"), tinitx=0)
 fit1.marss = MARSS(dat, model=mod.list1)
 mod.list2=list(
   B=matrix(1), U=matrix("u"), Q=matrix("q"),
   Z=matrix(1), A=matrix(0), R=matrix(0),
   x0=matrix("a"), tinitx=0)
 fit2.marss = MARSS(dat, model=mod.list2)
\end{Sinput}
\end{Schunk}
\begin{Schunk}
\begin{Sinput}
 coef(fit1.marss, type="vector")
\end{Sinput}
\begin{Soutput}
       Q.q       x0.a 
0.05156616 9.27537877 
\end{Soutput}
\begin{Sinput}
 coef(fit2.marss, type="vector")
\end{Sinput}
\begin{Soutput}
        U.u         Q.q        x0.a 
-0.09087941  0.04358239  9.36625818 
\end{Soutput}
\end{Schunk}
\item Which one appears better supported given AICc?
\begin{Schunk}
\begin{Sinput}
 c(fit1.marss$AICc, fit2.marss$AICc)
\end{Sinput}
\begin{Soutput}
[1]  0.6340661 -1.9336725
\end{Soutput}
\end{Schunk}
Model 2 is better supported with a $\Delta AICc$ of -2.56773865439913.
\item Load the \verb@forecast@ package. Use \verb@auto.arima(dat)@  to fit the data.  Next run \verb@auto.arima@ on the data with \verb@trace=TRUE@ to see all the ARIMA models it compared. 
\begin{Schunk}
\begin{Sinput}
 library(forecast)
 auto.arima(dat)
\end{Sinput}
\end{Schunk}
Let's look at all the models it tried using \verb@trace=TRUE@.
\begin{Schunk}
\begin{Sinput}
 auto.arima(dat, trace=TRUE)
\end{Sinput}
\begin{Soutput}
 ARIMA(2,1,2) with drift         : Inf
 ARIMA(0,1,0) with drift         : -2.855518
 ARIMA(1,1,0) with drift         : -0.7314056
 ARIMA(0,1,1) with drift         : Inf
 ARIMA(1,1,1) with drift         : Inf
 ARIMA(0,1,0)                    : -0.5520726

 Best model: ARIMA(0,1,0) with drift         

Series: dat 
ARIMA(0,1,0) with drift         

Coefficients:
        drift
      -0.0909
s.e.   0.0401

sigma^2 estimated as 0.0467:  log likelihood=3.66
AIC=-3.32   AICc=-2.86   BIC=-0.58
\end{Soutput}
\end{Schunk}
It picked model 2 as the best among those tested.  "ARIMA(0,1,0) with drift" is model 2.  

\item Is the difference in the AICc values between a random walk with and without drift comparable between MARSS() and auto.arima()?
\begin{Schunk}
\begin{Sinput}
 fit1.arima=Arima(dat, order=c(0,1,0))
 fit2.arima=Arima(dat, order=c(0,1,0), include.drift=TRUE)
 fit2.arima$aicc-fit1.arima$aicc
\end{Sinput}
\begin{Soutput}
[1] -2.303445
\end{Soutput}
\begin{Sinput}
 fit2.marss$AICc-fit1.marss$AICc
\end{Sinput}
\begin{Soutput}
[1] -2.567739
\end{Soutput}
\end{Schunk}
Similar but not identical.  BTW, to figure how to get AICc from an \verb@Arima()@ fit, I tried \verb@names(fit1.arima)@ and saw that AICc was in the element named \verb@aicc@.
\end{wideenumerate}

\subsection*{Problem 2}
This produces $x_t = x_{t-1} + u + w_t$ data with $u=0.1$ and $q=1$.
\begin{Schunk}
\begin{Sinput}
 dat=cumsum(rnorm(100,0.1,1))
\end{Sinput}
\end{Schunk}

\begin{wideitemize}
\item Write out the equation for that random walk as a univariate state-space model. 
\begin{equation}
\begin{gathered}
x_t = x_{t-1} + u + w_t, w_t \sim \N(0,q) \\
x_0 = \mu \text{ or } x_1 = y_1 \\
y_t = x_t
\end{gathered}
\end{equation}
where $u=0.1$ and $q=1$.
\item What is the order of the $\xx$ part of the model written as ARIMA(p, d, q)?  

\smallskip
From question 1, you should be able to deduce it is ARIMA(0,1,0) but if you said ARIMA(1,0,0) with b=1, that's ok.  That's not how \verb@Arima()@ writes $x_t = x_{t-1} + u + w_t$ but it is correct.
\item Fit that model using \verb@Arima()@ in the \verb@forecast@ package.  You'll need to specify the \verb@order@ and \verb@include.drift@ term.  
\begin{Schunk}
\begin{Sinput}
 fit.arima=Arima(dat, order=c(0,1,0), include.drift=TRUE)
\end{Sinput}
\end{Schunk}
\item Fit that model with \verb@MARSS()@.
\begin{Schunk}
\begin{Sinput}
 mod.list=list(
   B=matrix(1), U=matrix("u"), Q=matrix("q"),
   Z=matrix(1), A=matrix(0), R=matrix(0),
   x0=matrix("mu"), tinitx=0)
 fit.marss = MARSS(dat, model=mod.list)
\end{Sinput}
\end{Schunk}
or since I know that $x_1 = y_1$ from the observation model, I could use:
\begin{Schunk}
\begin{Sinput}
 mod.list.alt=list(
   B=matrix(1), U=matrix("u"), Q=matrix("q"),
   Z=matrix(1), A=matrix(0), R=matrix(0),
   x0=matrix(dat[1]), tinitx=1)
 fit.alt.marss = MARSS(dat, model=mod.list.alt, method="BFGS")
\end{Sinput}
\end{Schunk}
But hopefully you didn't try that because this makes the likelihood surface flat and you need to use lots more iterations or try a Newton method which happens to help (sometimes it doesn't or makes thing worse).
\item How are the two estimates different?
\begin{Schunk}
\begin{Sinput}
 coef(fit.marss, type="vector")
\end{Sinput}
\begin{Soutput}
      U.u       Q.q     x0.mu 
0.1436125 0.9974233 1.1039514 
\end{Soutput}
\begin{Sinput}
 coef(fit.alt.marss, type="vector")
\end{Sinput}
\begin{Soutput}
      U.u       Q.q 
0.1436125 1.0074993 
\end{Soutput}
\begin{Sinput}
 c(coef(fit.arima), s2=fit.arima$sigma2)
\end{Sinput}
\begin{Soutput}
    drift        s2 
0.1436125 1.0177789 
\end{Soutput}
\end{Schunk}
MARSS() is estimating 3 parameters while Arima() is estimating 2.  The $u$ estimates are identical but the $q$ estimate is different.

\smallskip
How did I know where to get the parameters estimates? \verb@coef()@ is the standard function for getting estimates from fits.  Try \verb@?coef@ to find the help file for \verb@coef@ applied to MARSS objects.  For Arima objects, \verb@coef()@ doesn't return sigma2 (which I discovered by trying \verb@coef(fit.arima)@).  So I did \verb@names(fit.arima)@ and found it was in \verb@fit.arima$sigma2@.
\end{wideitemize}

Now fit the first-differenced data:
\begin{Schunk}
\begin{Sinput}
 diff.dat=diff(dat)
\end{Sinput}
\end{Schunk}
\begin{wideitemize}
\item If $x_t$ denotes a time series.  What is the first difference of $x$?  What is the second difference?

\smallskip
First difference \verb@diff(x)@ is $x_t - x_{t-1}$.

Second difference is \verb@diff(diff(x))@ or $(x_t - x_{t-1}) - (x_{t-1} - x_{t-2})$.

\item What is the $\xx$ model for \verb@diff.dat@?
$$\text{diff}(x)=(x_t - x_{t-1}) = u + w_t$$
\item Fit \verb@diff.dat@ using \verb@Arima()@. You'll need to change \verb@order@ and \verb@include.mean@.
\begin{Schunk}
\begin{Sinput}
 fit.diff.arima=Arima(diff.dat, order=c(0,0,0), include.mean=TRUE)
\end{Sinput}
\end{Schunk}
\item Fit that model with \verb@MARSS()@.

data ($y$) is now diff.dat and state-space model is 
\begin{equation}
\begin{gathered}
x_t = u + w_t, w_t \sim \N(0,q) \\
x_0 = \mu \text{ or } x_1 = y_1 \\
y_t = x_t
\end{gathered}
\end{equation}
\begin{Schunk}
\begin{Sinput}
 mod.list.diff.1=list(
   B=matrix(0), U=matrix("u"), Q=matrix("q"),
   Z=matrix(1), A=matrix(0), R=matrix(0),
   x0=matrix(0), tinitx=0)
 fit.alt.diff.1 = MARSS(diff.dat, model=mod.list.diff.1)
 
\end{Sinput}
\end{Schunk}
Or we could have written it like so
\begin{equation}
\begin{gathered}
x_t = 0, w_t \sim \N(0,0) \\
x_0 = 0 \\
y_t = a + v_t, v_t \sim \N(0,r)
\end{gathered}
\end{equation}
In this case, we fit this model
\begin{Schunk}
\begin{Sinput}
 mod.list.diff.2=list(
   B=matrix(0), U=matrix(0), Q=matrix(0),
   Z=matrix(0), A=matrix("u"), R=matrix("r"),
   x0=matrix(0), tinitx=0)
 fit.alt.diff.2 = MARSS(diff.dat, model=mod.list.diff.2)
 
\end{Sinput}
\end{Schunk}
Here's the parameter estimates. They are all the same.
\begin{Schunk}
\begin{Sinput}
 coef(fit.alt.diff.1, type="vector")
\end{Sinput}
\begin{Soutput}
      U.u       Q.q 
0.1436125 1.0074983 
\end{Soutput}
\begin{Sinput}
 coef(fit.alt.diff.2, type="vector")
\end{Sinput}
\begin{Soutput}
      A.u       R.r 
0.1436125 1.0074983 
\end{Soutput}
\begin{Sinput}
 c(coef(fit.diff.arima), s2=fit.diff.arima$sigma2)
\end{Sinput}
\begin{Soutput}
intercept        s2 
0.1436125 1.0074983 
\end{Soutput}
\end{Schunk}
\end{wideitemize}

\subsection*{Problem 3}

%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
x_t = b x_{t-1}+u+w_t \text{ where } w_t \sim \N(0,q)  
\label{eq:gompertz}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~

\begin{wideitemize}
\item Write R code to simulate Equation \ref{eq:gompertz}.  Make $b$ less than 1 and greater than 0.  Set $u$ and $x_0$ to whatever you want.  You can use a \verb@for@ loop. 
\begin{Schunk}
\begin{Sinput}
 #set up my parameter values
 b=.8; u=2; x0=10; q=0.1
 nsim=1000
 #set up my holder for x
 x=rep(NA, nsim)
 x[1]=b*x0+u+rnorm(1,0,sqrt(q))
 for(t in 2:nsim) x[t]=b*x[t-1]+u+rnorm(1,0,sqrt(q))
\end{Sinput}
\end{Schunk}

\item Plot the trajectories and show that this model does not ``drift'' upward or downward.  It fluctuates about a mean value.
\begin{Schunk}
\begin{Sinput}
 plot(x, type="l",xlab="", ylab="x")
\end{Sinput}
\end{Schunk}
\begin{figure}[htp]
\begin{center}
\includegraphics{../figures/HWUSS--hw3-fig-plot}
\end{center}
\end{figure}

\item Hold $b$ constant and change $u$.  How do the trajectories change?
\begin{Schunk}
\begin{Sinput}
 #set up my parameter values
 u2=u+1
 x2=rep(NA, nsim)
 x2[1]=b*x0+u2+rnorm(1,0,sqrt(q))
 for(t in 2:nsim) x2[t]=b*x2[t-1]+u2+rnorm(1,0,sqrt(q))
 #second u
 u3=u-1
 x3=rep(NA, nsim)
 x3[1]=b*x0+u3+rnorm(1,0,sqrt(q))
 for(t in 2:nsim) x3[t]=b*x3[t-1]+u3+rnorm(1,0,sqrt(q))
 
\end{Sinput}
\end{Schunk}
\begin{figure}[htp]
\begin{center}
\includegraphics{../figures/HWUSS--hw3-fig-plot2}
\end{center}
\end{figure}
$u$ moves the mean of the trajectories up or down.


\item Hold $u$ constant and change $b$.  Make sure to use a $b$ close to 1 and another close to 0. How do the trajectories change?
\begin{Schunk}
\begin{Sinput}
 #set up my parameter values
 b1=0.9
 x0=u/(1-b1)
 x1=rep(NA, nsim)
 x1[1]=b1*x0+u+rnorm(1,0,sqrt(q))
 for(t in 2:nsim) x1[t]=b1*x1[t-1]+u+rnorm(1,0,sqrt(q))
 # second b
 b2=0.1
 x0=u/(1-b2)
 x2=rep(NA, nsim)
 x2[1]=b2*x0+u+rnorm(1,0,sqrt(q))
 for(t in 2:nsim) x2[t]=b2*x2[t-1]+u+rnorm(1,0,sqrt(q))
\end{Sinput}
\end{Schunk}
\begin{figure}[htp]
\begin{center}
\includegraphics{../figures/HWUSS--hw3-fig-plot3}
\end{center}
\end{figure}
The one with smaller $b$ has less auto-regression and is `tighter' (explores less of a range of the y axis).

\item Do 2 simulations each with the same $w_t$.  In one simulation, set $u=1$ and in the other $u=2$.  For both simulations, set $x_1 = u/(1-b)$.  You can set $b$ to whatever you want as long as $0<b<1$.  Plot the 2 trajectories on the same plot.  What is different?

\begin{Schunk}
\begin{Sinput}
 #set up my parameter values
 b=0.9
 u=1
 x0=u/(1-b)
 err=rnorm(nsim,0,sqrt(q))
 x1=rep(NA, nsim)
 x1[1]=b*x0+u+err[1]
 for(t in 2:nsim) x1[t]=b*x1[t-1]+u+err[t]
 # second u
 u=2
 x0=u/(1-b)
 x2=rep(NA, nsim)
 x2[1]=b*x0+u+err[1]
 for(t in 2:nsim) x2[t]=b*x2[t-1]+u+err[t]
\end{Sinput}
\end{Schunk}
\begin{figure}[htp]
\begin{center}
\includegraphics{../figures/HWUSS--hw3-fig-plot4}
\end{center}
\end{figure}
They are exactly the same except that the mean has changed from $1/(1-b)$ to $2/(1-b)$.  The mean level in the AR-1 model $x_t = b x_{t-1} + u + w_t$ is $u/(1-b)$.  For a given $b$, $u$ just changes the level.
\end{wideitemize}


\subsection*{Problem 4}
The MARSS package includes a data set of gray whales.  Load the data to use as follows:
\begin{Schunk}
\begin{Sinput}
 library(MARSS)
 dat=log(graywhales[,2])
\end{Sinput}
\end{Schunk}

Fit a random walk with drift model observed with error to the data:
%~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{equation}
\begin{gathered}
x_t = x_{t-1}+u+w_t \text{ where } w_t \sim \N(0,q) \\
y_t = x_t+v_t \text{ where } v_t \sim \N(0,r) \\
x_0 = a 
\end{gathered}   
\label{eq:marss.rw.w.drift}\end{equation}
%~~~~~~~~~~~~~~~~~~~~~~~~~
$y$ is the whale count in year $t$. $x$ is interpreted as the 'true' unknown population size that we are trying to estimate.

\begin{wideitemize}
\item Fit this model with \verb@MARSS()@
\begin{Schunk}
\begin{Sinput}
 mod.list=list(
   B=matrix(1), U=matrix("u"), Q=matrix("q"),
   Z=matrix(1), A=matrix(0), R=matrix("r"),
   x0=matrix("mu"), tinitx=0)
 fit.marss = MARSS(dat, model=mod.list)
\end{Sinput}
\end{Schunk}

\item Plot the estimated $x$ as a line with the actual counts added as points.
\begin{figure}[htp]
\begin{center}
\begin{Schunk}
\begin{Sinput}
 par(mar=c(2,2,2,2))
 plot(graywhales[,1], fit.marss$states[1,], type="l",xlab="", ylab="log count")
 points(graywhales[,1], dat)
\end{Sinput}
\end{Schunk}
\includegraphics{../figures/HWUSS--hw4-fig-plot1}
\end{center}
\end{figure}

\item Simulate 1000 sample trajectories using the estimated $u$ and $q$ starting at the estimated $x$ in 1997.  You can do this with a couple \verb@for@ loops or write something terse with \verb@cumsum@ and \verb@apply@.
\begin{Schunk}
\begin{Sinput}
 #1997 is the 39th (last) data point
 x0=fit.marss$states[1,39]
 q = coef(fit.marss)$Q
 u = coef(fit.marss)$U
 #next question asks for pop size in 2007 so nforeward=10
 nsim=1000
 nforeward = 10
 #each row holds a simulation
 x=matrix(NA, nsim, nforeward)
 x[,1]=x0+u+rnorm(nsim,0,sqrt(q))
 for(t in 2:nforeward) x[,t]=x[,t-1]+u+rnorm(nsim,0,sqrt(q))
\end{Sinput}
\end{Schunk}
\item Using this what is your estimated probability of reaching 50,000 graywhales in 2007.

\smallskip
The question was phrased a big vaguely.  It does not specify if this means ``in 2007, x=log(50000)'', ``at some point by or before 2007, x reaches log(50000) at least once'', or ``in 2007, the population is at least 50000 whales''.  I was thinking of the last one, but as long as you stated what you were trying to estimate, you were fine.
\begin{Schunk}
\begin{Sinput}
 #I just want the fraction of simulations that were 50,000 or above in 2007
 xthresh = log(50000)
 sum(x[,10]<=xthresh)/nsim
\end{Sinput}
\begin{Soutput}
[1] 0.594
\end{Soutput}
\end{Schunk}
\item What kind of uncertainty does that estimate NOT include?
\smallskip
By using the point estimates of $u$, $q$ and $x_0$, we are not including the uncertainty in those estimates in our forecasts.
\end{wideitemize}

\subsection*{Problem 5}
Fit the following 3 models to the graywhales data using MARSS(): 
\begin{enumerate}[label=\alph*.]
\item Process error only model with drift
\item Process error only model without drift
\item Process error with drift and observation error with observation error variance fixed = 0.05. 
\end{enumerate}
Process error only with drift. $x_t = x_{t-1} + u + w_t$ with $y_t = x_t$.
\begin{Schunk}
\begin{Sinput}
 mod.list=list(
   B=matrix(1), U=matrix("u"), Q=matrix("q"),
   Z=matrix(1), A=matrix(0), R=matrix(0),
   x0=matrix("mu"), tinitx=0)
 fit.whales1 = MARSS(dat, model=mod.list)
\end{Sinput}
\end{Schunk}
Process error only without drift. $x_t = x_{t-1} + w_t$ with $y_t = x_t$.
\begin{Schunk}
\begin{Sinput}
 mod.list=list(
   B=matrix(1), U=matrix(0), Q=matrix("q"),
   Z=matrix(1), A=matrix(0), R=matrix(0),
   x0=matrix("mu"), tinitx=0)
 fit.whales2 = MARSS(dat, model=mod.list)
\end{Sinput}
\end{Schunk}
Process error only with drift. $x_t = x_{t-1} + w_t$ with $y_t = x_t+v_t, v_t \sim N(0,0.05)$.
\begin{Schunk}
\begin{Sinput}
 mod.list=list(
   B=matrix(1), U=matrix("u"), Q=matrix("q"),
   Z=matrix(1), A=matrix(0), R=matrix(0.05),
   x0=matrix("mu"), tinitx=0)
 fit.whales3 = MARSS(dat, model=mod.list)
\end{Sinput}
\end{Schunk}
\begin{wideitemize}
\item Compute the AICc's for each model and likelihood or deviance (-2 * log likelihood)
\begin{Schunk}
\begin{Sinput}
 c(fit.whales1$AICc, fit.whales2$AICc, fit.whales3$AICc)
\end{Sinput}
\begin{Soutput}
[1] 2.131810 2.875514 3.760801
\end{Soutput}
\begin{Sinput}
 c(fit.whales1$logLik, fit.whales2$logLik, fit.whales3$logLik)
\end{Sinput}
\begin{Soutput}
[1] 2.5340949 0.8479575 1.7195997
\end{Soutput}
\end{Schunk}

\item Calculate a table of delta-AICc values and AICc weights. 
\begin{Schunk}
\begin{Sinput}
 AICc=c(fit.whales1$AICc, fit.whales2$AICc, fit.whales3$AICc)
 delAIC = AICc-min(AICc)
 relLik = exp(-0.5*delAIC)
 aic.table=data.frame(
   AICc = AICc,
   delAICc = delAIC,
   relLik = relLik/sum(relLik)
 )
 rownames(aic.table) = c(
   "proc only with drift", 
   "proc only no drift", 
   "proc with drift and obs error")
 round(aic.table, digits=3)
\end{Sinput}
\begin{Soutput}
                               AICc delAICc relLik
proc only with drift          2.132   0.000  0.469
proc only no drift            2.876   0.744  0.323
proc with drift and obs error 3.761   1.629  0.208
\end{Soutput}
\end{Schunk}
There is not much data support for including observation error with $r=0.05$.  But that is because $r=0.05$ is too big.  If we'd estimated $r$, like in problem 4, $r=$0.01.  With this $r$, the process error with drift and observation error model would be best (AICc=1.98).
\end{wideitemize}

\subsection*{Problem 6}
Fit the following four models and calculate the MASE statistic for each (using the forecasts for the 3 data points): ARIMA(0,0,0), ARIMA(1,0,0), ARIMA(0,0,1), ARIMA(1,0,1). Present them in a table similar to what Eric showed in lecture. 

Load the data to use as follows and set up so you can use the last 3 data points to validate your fits. 
\begin{Schunk}
\begin{Sinput}
 require(forecast)
 dat=log(airmiles)
 n = length(dat)
 training.dat = dat[1:(length(airmiles)-3)]
 test.dat = dat[(length(airmiles)-2):n]
\end{Sinput}
\end{Schunk}

First fit the models with \verb@Arima@:
\begin{Schunk}
\begin{Sinput}
 fit.1=Arima(training.dat, order =c(0,0,0))
 fit.2=Arima(training.dat, order =c(1,0,0))
 fit.3=Arima(training.dat, order =c(0,0,1))
 fit.4=Arima(training.dat, order =c(1,0,1))
\end{Sinput}
\end{Schunk}
Then forecast forward 3 steps with the fits (output shown for forecast 1):
\begin{Schunk}
\begin{Sinput}
 forecast.1=forecast(fit.1, h=3)
 forecast.2=forecast(fit.2, h=3)
 forecast.3=forecast(fit.3, h=3)
 forecast.4=forecast(fit.4, h=3)
 forecast.1
\end{Sinput}
\begin{Soutput}
   Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
22       8.350627 6.717672 9.983582 5.853238 10.84802
23       8.350627 6.717672 9.983582 5.853238 10.84802
24       8.350627 6.717672 9.983582 5.853238 10.84802
\end{Soutput}
\end{Schunk}
Then you can use the accuracy function to calculate the MASE statistic. 
\begin{Schunk}
\begin{Sinput}
 accuracy(forecast.1, test.dat)
\end{Sinput}
\begin{Soutput}
                        ME     RMSE      MAE       MPE
Training set -4.228079e-16 1.274201 1.121923 -2.565641
Test set      1.899534e+00 1.901199 1.899534 18.526816
                 MAPE     MASE    ACF1
Training set 14.26941 5.391961 0.85469
Test set     18.52682 9.129155      NA
\end{Soutput}
\end{Schunk}
The MASE statistic we want is in the Test set row and MASE column.  We will put the MASE statistics together in a table.
\begin{Schunk}
\begin{Sinput}
 MASEs = c(
   accuracy(forecast.1, test.dat)["Test set","MASE"],
   accuracy(forecast.2, test.dat)["Test set","MASE"],
   accuracy(forecast.3, test.dat)["Test set","MASE"],
   accuracy(forecast.4, test.dat)["Test set","MASE"]
 )
 data.frame(
   name=paste("Arima",c("(0,0,0)","(1,0,0)","(0,0,1)","(1,0,1)"),sep=""), 
   MASE=MASEs
   )
\end{Sinput}
\begin{Soutput}
          name      MASE
1 Arima(0,0,0) 9.1291550
2 Arima(1,0,0) 0.6906049
3 Arima(0,0,1) 7.7353124
4 Arima(1,0,1) 0.5119703
\end{Soutput}
\end{Schunk}
What this shows is that the ARMA(1,0,1) is the best, and the AR component strongly improves predictions

